\documentclass[FinalReport.tex]{subfiles}
\begin{document}
Complex systems, sometimes described intuitively as "wholes that are more than the sum of their parts", are systems where a large collections of locally dependent elements may spontaneously self-organize to produce non-trivial collective phenomenon. Those systems exhibit extreme events much more frequently than expected with normally distributed sequences. Their tail distribution is often described by power laws $P(z)\sim z^{-(1+\mu)}$, which present very specific properties. They reflect self-similar structures thanks to scale invariance and, more importantly here, posses a well-defined variance only $\mu>2$, implying the occurrence of extreme events sometimes referred as Black Swans.

Such distributions appear in numerous natural and artificial phenomenon. In physics for example, they describe the behavior of order parameters at the critical points for second order phase transitions. Alternatively, \citet{Beggs} demonstrated that propagation of spontaneous activity in cortical networks is described by the same equations than avalanches, with exponent $\mu=1/2$. In economics, \citet{pareto} observed that wealth distribution is heavy tailed, introducing the famous $80-20$ principle. Few years later, \citet{estoup1916} remarked that rank frequency distribution of words also follows a power law, later formalized by \citet{zipf}. In particular, experiments of visuomotor control of a virtual target in \citet{Bormann} demonstrated that deviations from a target are power law distributed. By studying the balancing of a stick at the fingertip \citet{on-off-balancing} found the same distribution for fluctuations around some target value, characteristic of on-off intermittency. 

To model those experiments, a simplified one dimensional control algorithm employing "optimal" estimation of an unknown excitation parameter was proposed by \citet{OptCont}. Resulting system self-organizes into a critical regime, producing heavy tailed fluctuations. This scaling behavior was attributed to the multiplicative noise process resulting from optimal parameter estimation.  
 
Taking this model as starting point we investigate the validity of control methodology, in particular it's so-called optimality, to explain the deep origin of power law distributed fluctuations. Besides, we study the complex dependence of final distribution on the length of the observation period. 

Optimal parameter estimation takes its names from the use of well-known Maximum Likelihood Estimator (MLE), which indeed yields very good results when the number of samples is large, thanks to the Central Limit Theorem (CLT, \citet{CoxHink74}). In our case, when memory is short (typically less than $10$ past observations), those properties clearly do not hold. Indeed, the estimator involves sample variance of the time series on which the control is learned at its denominator. When fluctuations get close to the origin, the denominator thus goes to $0$ and the estimator diverges. For the extreme case with a unique past observation, we re-derive the exponent $\mu=1$ already computed analytically in \citet{FrontNanoScience} and recover the postulated linear relation between the length of observation $n$ with the scaling exponent $\mu$.
 
However, with more memory numerical simulations demonstrate 
that generated time series follow noise distribution which defines of optimal control. In this context the random map takes the form of a Kesten process, a mixture of multiplicative and additive processes, which are known to produce power law distributed sequences (\citet{kesten}). This asymptotic theory provides a qualitative way to relate the tail exponent of the distribution with memory length. As power laws, Kesten processes arise in various fields, including economics \cite{kesten-econ} or physics of disordered systems \cite{kesten-process-physics}. More interestingly here, \citet{kesten-synapses} applied it to model qualitatively synaptic size dynamics. They were able to recover the shape and long-term stability of experimentally observed synaptic size distributions. 


Finally, we propose a natural modification of the control strategy for the very short memory case, by replacing the original estimator with a constant when the time series starts diverging. Despite its apparent naivety, adding this regularization prevents extreme deviations for well-chosen parameters.
\begin{comment}

The guiding idea is to study the nature of the control methodology, and the dependence of the results on the length of the time series on which the control is learned. In particular,  the emerging power-​laws can be seen to be structurally similar to the denominator of the random variable at the origin of the introduction of the student t distribution. We want to test the conjecture that the effects found by Eurich and Pawelzik (2005) and Patzelt et al may in fact disappear in certain very relevant conditions that will be explained to the student.
	
\end{comment}


  
\end{document}
